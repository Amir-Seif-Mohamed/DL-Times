{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation using PyTorch.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aVu0N4qjNnjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Translation with a Sequence to Sequence Network and Attention"
      ]
    },
    {
      "metadata": {
        "id": "D8lSPJzXNnjy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training a neural network to convert a German Sentence to English Sentence.\n",
        "\n",
        "Notes :  \n",
        "This is made possible by the simple yet powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another sequence. An `encoder` network condenses an input sequence into a vector, and a `decoder` network unfolds that vector into a new sequence.\n",
        "\n",
        "<img src = 'https://pytorch.org/tutorials/_images/seq2seq.png'/>\n",
        "\n",
        "To improve upon this model we will use an `attention mechanism`, which lets the decoder learn to focus over a specific range of the input sequence."
      ]
    },
    {
      "metadata": {
        "id": "uSimAhcFNnj0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing Requirements"
      ]
    },
    {
      "metadata": {
        "id": "Y6h-Qh5FNrd4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "18256df4-e641-4082-b3cc-91991111c8ea",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531998350638,
          "user_tz": -330,
          "elapsed": 42073,
          "user": {
            "displayName": "Mayank Mishra",
            "photoUrl": "//lh3.googleusercontent.com/-iO90Mbedp78/AAAAAAAAAAI/AAAAAAAAADE/LUTBLCQACQU/s50-c-k-no/photo.jpg",
            "userId": "109554884281440712123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c536000 @  0x7fea54f861c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7-f7pfsjNnj1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, division, print_function\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-HCpGcfNnj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading Data Files**\n",
        "\n",
        "The data for this project is collection og English to German translation pairs.  \n",
        "Thanks to <a href = 'http://www.manythings.org/anki/'> here </a> for providing the data.  \n",
        "The data for this is available at data/eng-deu.txt. The file is a tab separated list of translation pairs:  \n",
        "  \n",
        "I ran. &emsp; Ich rannte.\n",
        "  \n",
        "We will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language."
      ]
    },
    {
      "metadata": {
        "id": "js41uYNiNnj7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We’ll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Lang` which has `word → index` (word2index) and `index → word` (index2word) dictionaries, as well as a count of each word `word2count` to use to later replace rare words."
      ]
    },
    {
      "metadata": {
        "id": "0fmpHdeKNnj9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.index2word = {0 : 'SOS', 1 : 'EOS'}\n",
        "        self.word2count = {}\n",
        "        self.n_words = 2 # count for SOS and EOS\n",
        "    \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niApaZ-2Nnj_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# The files are in Unicode strings therefore to simplify converting these \n",
        "# string to ASCII format, trim punctuations and convert them in lower case\n",
        "\n",
        "def strip_accents(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Lowercase, trim and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = strip_accents(s.lower().strip())\n",
        "    s = re.sub(r'([.!?])', r'\\1', s)\n",
        "    s = re.sub(r'[^a-zA-z.!?]+', r' ', s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGp5l7Y5NnkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To read the data file we will spilt the content of file in lines and then into pairs. The files are all `English -->> German`, so if we want to translate from `German -->> English` then can use the reversed flag. "
      ]
    },
    {
      "metadata": {
        "id": "7BaBaDICNnkD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def readlangs(lang1, lang2, reverse = False):\n",
        "    print('-' * 100)\n",
        "    print('Reading lines .....')\n",
        "    print('-' * 100)\n",
        "    \n",
        "    # Reading lines and Splitting it into pairs\n",
        "    with open('data/{}-{}.txt'.format(lang1, lang2), encoding = 'utf-8') as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "        \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "        \n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T_FKgWWNnkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First let's do some experimentation talking sentences with max length of 10. With a few more filtering applied"
      ]
    },
    {
      "metadata": {
        "id": "zHmNzWwFNnkH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    'i am', 'i m',\n",
        "    'he is', 'he s',\n",
        "    'she is', 'she s',\n",
        "    'you are', 'you re',\n",
        "    'we are', 'we re',\n",
        "    'they are', 'they re',\n",
        "    'it is', 'it s',\n",
        "    'i will', 'i ll',\n",
        "    'let us', 'let s',\n",
        "    'we will', 'we ll',\n",
        "    'do not', 'don t',\n",
        "    'here is', 'here s',\n",
        "    'i would', 'i d',\n",
        "    'what is', 'what s',\n",
        "    'who will', 'who ll',\n",
        "    'that will', 'that ll',\n",
        "    'that is', 'that s',\n",
        "    'this will' ,'this ll',\n",
        "    'you have', 'you ve',\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "           len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "           p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-bLOEirNnkK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Describing the text processing steps**\n",
        "  \n",
        "The full process of text preperation is as follows:\n",
        " - Read text file and split it into lines, split lines into pairs\n",
        " - Normalize text, filter by length and content\n",
        " - Make word lists from sentences in pairs "
      ]
    },
    {
      "metadata": {
        "id": "LjthB9cmNnkL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "8f47f220-bfd6-41b0-c180-044f540a3c9f",
        "executionInfo": {
          "status": "error",
          "timestamp": 1531998365477,
          "user_tz": -330,
          "elapsed": 1580,
          "user": {
            "displayName": "Mayank Mishra",
            "photoUrl": "//lh3.googleusercontent.com/-iO90Mbedp78/AAAAAAAAAAI/AAAAAAAAADE/LUTBLCQACQU/s50-c-k-no/photo.jpg",
            "userId": "109554884281440712123"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse = False):\n",
        "    input_lang, output_lang, pairs = readlangs(lang1, lang2, reverse)\n",
        "    print('Read {} sentence pairs.'.format(len(pairs)))\n",
        "\n",
        "    pairs = filterPairs(pairs)\n",
        "    print('Trimmed to {} number of pairs.'.format(len(pairs)))\n",
        "    \n",
        "    print('-' * 100)\n",
        "    print('Counting of word is starting .....')\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print('Counted Words Stats : ')\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    print('-' * 100)\n",
        "    \n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'deu', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Reading lines .....\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-005edbd16104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-005edbd16104>\u001b[0m in \u001b[0;36mprepareData\u001b[0;34m(lang1, lang2, reverse)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadlangs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Read {} sentence pairs.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterPairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-9b68ce8987ca>\u001b[0m in \u001b[0;36mreadlangs\u001b[0;34m(lang1, lang2, reverse)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Reading lines and Splitting it into pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/{}-{}.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/eng-deu.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WKWn_jGKNnkR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Sequence to Sequence Model\n",
        "  \n",
        "A Recurrent Neural Network rather RNN is a neural network that operates on a sequence and uses its own output as input for subsequent time steps.\n",
        "  \n",
        "A `Sequence to Sequence network` or seq2seq network or `Encoder Decoder Network`, is a model consisting of two RNN called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.\n",
        "  \n",
        "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.\n",
        "  \n",
        "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the \"meaning\" of the input sequence into a single vector - a single point in some N dimensional space of sentences.\n",
        "This single vector is often called as `context vector`."
      ]
    },
    {
      "metadata": {
        "id": "IT5bh9sFNnkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The Encoder**\n",
        "  \n",
        "The Encoder of a seq2seq model is a RNN that output some kind of value for every word from the input sentence. For every input it outputs a vector and a hidden state which in turn will be used as input for next word. \n",
        "  \n",
        "The diagram for illustrating the above written description is shown below:\n",
        "  \n",
        "<img src = 'https://pytorch.org/tutorials/_images/encoder-network.png'/>"
      ]
    },
    {
      "metadata": {
        "id": "1-QWykWUNnkT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "            \n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cxeekVI-NnkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The Decoder**  \n",
        "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
        "  \n",
        "<b>Simple Decoder</b>  \n",
        "In the simplest se2seq decoder we use only last output of the encoder. This last output is sometimes called as the `context vector` as it encodes context from the entire sequence. This context vector is used  as the initial hidden state of the decoder.\n",
        "  \n",
        "At every step of the decoding, the decoder is given an input tokken and hidden state. The initial input token is `<sos>` token, and the first hidden state is the context vector (the encoder's last hidden state).\n",
        "\n",
        "<img src = 'https://pytorch.org/tutorials/_images/decoder-network.png'/>"
      ]
    },
    {
      "metadata": {
        "id": "nmE4c2Z0NnkZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        \n",
        "        self.lin = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 1)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.lin(output[0])\n",
        "        output = self.softmax(output)\n",
        "        \n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OejIc3QINnkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b>Attention Decoder</b>\n",
        "  \n",
        "If only the context vector is passed between the encoder and decoder, that single vector carries the burden of encoding the entire sentence.\n",
        "  \n",
        "Attention allows the decoder network to \"focus\" on a different part of the encoder's output for every time step for decoder's output. For this we need to calculate a set of attention weights. These weights will be multiplied with the encoder's output vector to create a weighted combination. The result should contains the information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
        "  \n",
        "<img src = 'https://i.imgur.com/1152PYf.png'/>\n",
        "  \n",
        "Calculating the attention weights is carried out by another feed forward neural network setup that takes in input the output of the Encoder (which will serve as input for the decoder) and the previous hidden state of the Decoder Network and then passed through a softmax gate. The resultant of this gate serve as the attention vector for the ith input and the t-th output. The weights are calculated in such a fashion that all the attention vector calculated for getting the t-th output when summed uo will result in a unit vector.\n",
        "\n",
        "The graph for such a Attention based RNN is shown below :\n",
        "  \n",
        "<img src = 'https://pytorch.org/tutorials/_images/attention-decoder-network.png'/>\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "o6QkAUpvNnke",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class AttentionDecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention Based Decoder RNN\n",
        "    \n",
        "    ARGS:\n",
        "     -> hidden_size - type : int - number of hidden dimensions\n",
        "     -> output_size - type : int - output size\n",
        "     -> dropout_p - type : float - the dropout percentage\n",
        "     -> max_length - type : int - the maximum permissible length of the sentences\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, output_size, \n",
        "                 dropout_p = 0.1, max_length = MAX_LENGTH):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combined = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        \n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        attn_out = self.attn(torch.cat((embedded[0], hidden[0]), 1))\n",
        "        attn_weights = F.softmax(attn_out, dim = 1)\n",
        "        \n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), \n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "        \n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combined(output).unsqueeze(0)\n",
        "        output = F.relu(output)\n",
        "        \n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "        \n",
        "        output = F.log_softmax(output, dim = 1)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfhA7bdeNnkg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "  \n",
        "**Preparing Training Data**  \n",
        "  \n",
        "To train, for each pair we will need an input tensor (indexes of words in the input sentence) and target tensor (indexes of words in the target sentence). While Creating both the tensors we will create the EOS token to both the sequences."
      ]
    },
    {
      "metadata": {
        "id": "CVDyGwpDNnkh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def indexesFromSentences(lang, sentences):\n",
        "    return [lang.word2index[word] for word in sentences.split(' ')]\n",
        "\n",
        "def tensorFromSentences(lang, sentences):\n",
        "    indexes = indexesFromSentences(lang, sentences)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype = torch.long, device = device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "    input_tensor = tensorFromSentences(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentences(output_lang, pair[1])    \n",
        "    return(input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwPwve9qNnkn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training the Model**\n",
        "  \n",
        "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state.  Then the decoder is given the `<sos>` token as its first input, and the last hidden state of the encoder as its first hidden state.\n",
        "\n",
        "`\"Teacher Forcing\"` is the concept of using the real target output as input to the next step, instead of using the decoder's guess as the next input. Using Teacher Forcing causes model to converge faster but when the trained model is exploited, it may exhibit instability.\n",
        "  \n",
        "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.\n",
        "\n",
        "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement. Turn `teacher_forcing_ratio` up to use more of it."
      ]
    },
    {
      "metadata": {
        "id": "iLzNjK15Nnko",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion, max_length = MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    \n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    \n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
        "    \n",
        "    loss = 0\n",
        "    \n",
        "    for encod_in in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "                                    input_tensor[encod_in], encoder_hidden)\n",
        "        \n",
        "        encoder_outputs[encod_in] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device = device)\n",
        "    \n",
        "    decoder_hidden = encoder_hidden\n",
        "    \n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    \n",
        "    if use_teacher_forcing:\n",
        "        # Using teacher forcing feeding the target tensor as input\n",
        "        # rather then its own guess\n",
        "        for decod_in in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                         decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[decod_in])\n",
        "            decoder_input = target_tensor[decod_in] # teacher facing\n",
        "        \n",
        "    else:\n",
        "        # With out teacher forcing using its on guess as input\n",
        "        for decod_in in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                        decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[decod_in])\n",
        "            \n",
        "            # Getting the top k guess of decoder\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() # detachinf it from the history\n",
        "            \n",
        "            if decoder_input.item == EOS_token:\n",
        "                break\n",
        "        \n",
        "    loss.backward()\n",
        "    \n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOeEf9X9Nnkr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is a helper function to print time elapsed and estimated time remaining given the current time and progress in percentages."
      ]
    },
    {
      "metadata": {
        "id": "QRbAr1y4Nnkt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '{}m {}s'.format(m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / percent\n",
        "    rs = es - s\n",
        "    return '{} (- {})'.format(asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZ4VWMPaNnkv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The whole training process looks like :\n",
        "- Start timer\n",
        "- Initialize optimizers and criterions\n",
        "- Create set of training pairs\n",
        "- Start empty losses array for plotting\n",
        "  \n",
        "Then we will invoke `train()` several times and eventually will print the progress (percent of examples, time so far, estimated time) and average loss"
      ]
    },
    {
      "metadata": {
        "id": "fHHEDHLxNnkx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every = 100,\n",
        "               plot_every = 100, learning_rate = 0.01):\n",
        "    \"\"\"\n",
        "        This function will kick off the training procedure and train the enitire Seq2Seq network.\n",
        "        At a wild level, this will take the arguments and invoke the train() passing the arguments\n",
        "        Also will print stats related to training phase like avaerage loss and plot graph based on \n",
        "        arguments specified.\n",
        "        \n",
        "        ARGS :\n",
        "        # encoder - reference to encoder class.\n",
        "        # decoder - reference to decoder class.\n",
        "        # n_ters - number of iteration to do for training network.\n",
        "        # print_every, plot_every - number of iteration after which to print and plot stats respectively.\n",
        "        # learning_rate : learning rate for the network.\n",
        "    \"\"\"\n",
        "    # Step 1 : Starting timer\n",
        "    start = time.time()\n",
        "    \n",
        "    # Step 2: Initialize optimizers and criterion\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "    \n",
        "    # Step 3: Creating sets of training pairs\n",
        "    training_pairs = [tensorFromPair(random.choice(pairs))\n",
        "                      for _ in range(n_iters)]\n",
        "    \n",
        "    # Step 4: Start empty losse array for plotting\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 # Resets every print_every\n",
        "    plot_loss_total = 0 # Resets every plot_every\n",
        "    \n",
        "    # Kicking off the Training\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        \n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
        "                     encoder_optimizer, decoder_optimizer, criterion)\n",
        "        \n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "        \n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTg0vv1INnk1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Plotting Results**\n",
        "  \n",
        "Plotting is done using matplotlib, using the array of loss values `plot_losses` saved during the training."
      ]
    },
    {
      "metadata": {
        "id": "SaV3-8gyNnk1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJR_x61TNnk6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at multiple places\n",
        "    loc = ticker.MultipleLocator(base = 0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_1-spGtKNnk7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evalutaion**\n",
        "  \n",
        "Evaluation is same mostly as the training, but there are no targets so we simply feed the decoder's prediction back to itself for each step. Every time it predicts a word we will add it to output strings, and if predicts EOS token we stop there. We also store the decoder's attention output for display later."
      ]
    },
    {
      "metadata": {
        "id": "ac5r6AfoNnk8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def evalutate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentences(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        \n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n",
        "        \n",
        "        for encod_in in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[encod_in], \n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[encod_in] = encoder_output[0, 0]\n",
        "            \n",
        "        decoder_input = torch.tensor([[EOS_token]], device = device)\n",
        "        \n",
        "        decoder_hidden = encoder_hidden\n",
        "        \n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "        \n",
        "        for decod_in in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                        decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attention[decod_in] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoder_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            \n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        \n",
        "        return decoded_words, decoder_attentions[:decod_in + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tN0HhHoDNnk_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
      ]
    },
    {
      "metadata": {
        "id": "oTfDaCG-NnlA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('-' * 100)\n",
        "        print('-->', pair[0])\n",
        "        print('<--', pair[1])\n",
        "        print('-' * 100)\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('', output_sentence)\n",
        "        print('')\n",
        "        print('-' * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AVSROpU9NnlE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training and Evaluating**\n",
        "\n",
        "For the filtered dataset we will use a samll network of 260 hidden nodes and a single GRU layer. Let's see how much time it will take on a system with following specifications:\n",
        "  \n",
        "- Processor : Intel® Core™ i5-4440S CPU @ 2.80GHz × 4 \n",
        "- Memory : 15.5 GiB\n",
        "- OS : 64-bit Ubuntu 18.04 LTS\n",
        "  \n",
        "on CPU based training machine."
      ]
    },
    {
      "metadata": {
        "id": "kCxjCTZmNnlE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 260\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttentionDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iiuwCjJNnlG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}