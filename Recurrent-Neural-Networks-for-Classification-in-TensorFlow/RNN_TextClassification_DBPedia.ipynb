{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "n_words = 0\n",
    "MAX_LABEL = 15\n",
    "WORDS_FEATURE = 'words'      # None of the input words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia = tf.contrib.learn.datasets.load_dataset(\n",
    "                'dbpedia', size = 'small', test_with_fake_data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbpedia.train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbpedia.test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(dbpedia.train.data)))\n",
    "\n",
    "data_shuffled = dbpedia.train.data[shuffle_indices]\n",
    "target_shuffled = dbpedia.train.target[shuffle_indices]\n",
    "\n",
    "train_data = data_shuffled[:]\n",
    "train_target = target_shuffled[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.random.permutation(np.arange(len(dbpedia.test.data)))\n",
    "\n",
    "data_shuffled = dbpedia.test.data[shuffle_indices]\n",
    "target_shuffled = dbpedia.test.target[shuffle_indices]\n",
    "\n",
    "\n",
    "test_data = data_shuffled[:]\n",
    "test_target = target_shuffled[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Alina Orlova',\n",
       "        ' Alina Orlova (lithuanian. Alina Orlovskaja polish Alina Orłowska born June 28 1988) is a Lithuanian sung poetry singer and musician. She is of mixed Polish-Russian heritage.'],\n",
       "       ['HMS Carysfort (1836)',\n",
       "        ' HMS Carysfort was a sixth-rate sailing frigate of the Royal Navy launched in 1836 and named for the Earl of Carysfort who had been a former (civilian) Lord of the Admiralty. Her captain Lord George Paulet occupied the Hawaiian Islands for five months in 1843. She was decommissioned in 1847 and finally broken up in 1861.'],\n",
       "       ['Chinspot Batis',\n",
       "        ' The chinspot batis (Batis molitor) is a species of bird in the Platysteiridae family.It is found in Angola Botswana Burundi Republic of the Congo Democratic Republic of the Congo Gabon Kenya Lesotho Malawi Mozambique Namibia Rwanda South Africa Sudan Swaziland Tanzania Uganda Zambia and Zimbabwe.Its natural habitats are subtropical or tropical dry forests subtropical or tropical moist lowland forests subtropical or tropical moist montane forests and dry savanna.The chin-spot is a common and widespread bird and is primarily insectivorous finding its food on the surfaces of leaves and occasionally catching insects on the wing. '],\n",
       "       ['Sargrefteh',\n",
       "        ' Sargrefteh (Persian: سرگرفته\\u200e; also known as Tāleqānī) is a village in Jelogir Rural District in the Central District of Pol-e Dokhtar County Lorestan Province Iran. At the 2006 census its population was 32 in 5 families.'],\n",
       "       ['Dukhulal Nibaran Chandra College',\n",
       "        ' Dukhulal Nibaran Chandra College established in 1967 is one of the oldest college in Aurangabad in Murshidabad district. It offers undergraduate courses in arts commerce and sciences. It is affiliated to University of Kalyani.']],\n",
       "      dtype='<U750')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dbpedia.train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.Series(train_data[:, 1])\n",
    "y_train = pd.Series(train_target)\n",
    "\n",
    "x_test = pd.Series(test_data[:, 1])\n",
    "y_test = pd.Series(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 83\n"
     ]
    }
   ],
   "source": [
    "max_document_length_train = max(len(x.split(\" \")) for x in x_train)\n",
    "max_document_length_test = max(len(x.split(\" \")) for x in x_test)\n",
    "\n",
    "print(max_document_length_train, max_document_length_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = max(max_document_length_train, \n",
    "                          max_document_length_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(\n",
    "                    MAX_DOCUMENT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(list(vocab_processor.fit_transform(x_train)))\n",
    "x_test = np.array(list(vocab_processor.fit_transform(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   1,   4,   5,   1,   6,   7,   8,   9,  10,  11,\n",
       "         12,  13,  14,  15,  16,  17,  18,  19,  11,  20,  21,  22,  23,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 24,  25,  26,  12,  27,  28,  29,  20,  30,  31,  32,  33,  34,\n",
       "         35,  17,  36,  37,  30,  38,  20,  25,  39,  40,  41,  12,  42,\n",
       "         43,  44,  20,  30,  45,  46,  47,  44,  48,  49,  50,  30,  51,\n",
       "         52,  37,  53,  54,  34,  55,  19,  26,  56,  34,  57,  17,  58,\n",
       "         59,  60,  34,  61,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 62,  63,  64,  65,  66,  11,  12,  67,  20,  68,  34,  30,  69,\n",
       "         70,  71,  11,  72,  34,  73,  74,  75,  76,  20,  30,  77,  78,\n",
       "         76,  20,  30,  77,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "         88,  89,  90,  91,  92,  17,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102,  98,  99, 100, 103, 104, 102,  98,  99, 100, 103,\n",
       "        105, 102,  17, 101, 106,  62, 107,  11,  12, 108,  17, 109,  68,\n",
       "         17,  11, 110, 111, 112, 113, 114, 115,  30, 116,  20, 117,  17,\n",
       "        118, 119, 120, 115,  30, 121,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Alina Orlova',\n",
       "        ' Alina Orlova (lithuanian. Alina Orlovskaja polish Alina Orłowska born June 28 1988) is a Lithuanian sung poetry singer and musician. She is of mixed Polish-Russian heritage.'],\n",
       "       ['HMS Carysfort (1836)',\n",
       "        ' HMS Carysfort was a sixth-rate sailing frigate of the Royal Navy launched in 1836 and named for the Earl of Carysfort who had been a former (civilian) Lord of the Admiralty. Her captain Lord George Paulet occupied the Hawaiian Islands for five months in 1843. She was decommissioned in 1847 and finally broken up in 1861.'],\n",
       "       ['Chinspot Batis',\n",
       "        ' The chinspot batis (Batis molitor) is a species of bird in the Platysteiridae family.It is found in Angola Botswana Burundi Republic of the Congo Democratic Republic of the Congo Gabon Kenya Lesotho Malawi Mozambique Namibia Rwanda South Africa Sudan Swaziland Tanzania Uganda Zambia and Zimbabwe.Its natural habitats are subtropical or tropical dry forests subtropical or tropical moist lowland forests subtropical or tropical moist montane forests and dry savanna.The chin-spot is a common and widespread bird and is primarily insectivorous finding its food on the surfaces of leaves and occasionally catching insects on the wing. ']],\n",
       "      dtype='<U750')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words :  7552\n"
     ]
    }
   ],
   "source": [
    "n_words = len(vocab_processor.vocabulary_)\n",
    "\n",
    "print(\"Total words : \", n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator_spec_for_softmax_classification(logits, labels, mode):\n",
    "    \n",
    "    #Prediction mode\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                mode = mode,\n",
    "                predictions={\n",
    "                    'class': predicted_classes,\n",
    "                    'prob' : tf.nn.softmax(logits)\n",
    "                })\n",
    "    \n",
    "    #Training Mode\n",
    "    onehot_labels = tf.one_hot(labels, MAX_LABEL, 1, 0)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels = onehot_labels, logits = logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss = loss, train_op=train_op)\n",
    "    \n",
    "    # Evaluation Mode\n",
    "    eval_metric_ops = {\n",
    "        'accuracy' : tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predicted_classes)\n",
    "    } \n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(features, labels, mode):\n",
    "    word_vector = tf.contrib.layers.embed_sequence(\n",
    "        features[WORDS_FEATURE], vocab_size=n_words, embed_dim=EMBEDDING_SIZE)\n",
    "    \n",
    "    word_list = tf.unstack(word_vector, axis = 1)\n",
    "    \n",
    "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
    "    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "    \n",
    "    logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "    \n",
    "    return estimator_spec_for_softmax_classification(\n",
    "            logits = logits, labels = labels, mode = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpyw3n7tje\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpyw3n7tje', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe46134c128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "clasifier = tf.estimator.Estimator(model_fn=rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpyw3n7tje/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 101 into /tmp/tmpyw3n7tje/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.007276279, step = 101\n",
      "INFO:tensorflow:Saving checkpoints for 110 into /tmp/tmpyw3n7tje/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.005432175.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fe46134c8d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                    x = {WORDS_FEATURE : x_train},\n",
    "                    y = y_train,\n",
    "                    batch_size = len(x_train),\n",
    "                    num_epochs = 10,\n",
    "                    shuffle = True\n",
    ")\n",
    "\n",
    "clasifier.train(input_fn=train_input_fn, steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "                    x = {WORDS_FEATURE : x_test},\n",
    "                    y = y_test,\n",
    "                    num_epochs = 1,\n",
    "                    shuffle = False\n",
    ")\n",
    "\n",
    "predict = clasifier.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpyw3n7tje/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "y_predict = np.array(list(p['class'] for p in predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = y_predict.reshape(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  8,  4,  1,  3,  7,  7,  6, 11,  8,  5,  8, 11,  8,  9, 12, 11,\n",
       "       11, 14,  3,  2, 11,  7,  9, 10,  3,  1,  5, 12,  9, 12,  3,  3,  1,\n",
       "        5,  1,  1,  5, 11,  7, 11,  9,  7,  8, 12,  1,  6,  1,  6,  4,  7,\n",
       "        4, 11, 11, 11, 11,  1,  5, 12,  1,  1, 12, 12, 11, 10,  3,  5,  8,\n",
       "        2, 12])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (sklearn) : 41.428571\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_test, y_predict)\n",
    "\n",
    "print('Accuracy (sklearn) : {0:f}'.format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
