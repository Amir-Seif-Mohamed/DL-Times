{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handwritten digit classification on MNIST data using CNN<br>\n",
    "<ul>\n",
    "<li>Simple CNN with 2 convolutional layer and one pooling layer</li>\n",
    "<li>Measure the accuracy of the algorithm on the test data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(digit):\n",
    "    plt.imshow(digit.reshape(28, 28), cmap = 'Greys', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_digits, training_labels = mnist.train.next_batch(1000)\n",
    "test_digits, test_labels = mnist.test.next_batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(training_digits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_feature_maps = 32\n",
    "conv1_kernel_size = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = 'SAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding = 'SAME' -- Uses zero-padding to ensure pixels at the edges are included <br/>\n",
    "padding = 'VALID' -- No zero padding, pixels at the edges are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_feature_maps = 64\n",
    "conv2_kernel_size = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = 'SAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool3_feature_maps = conv2_feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fullyconn1 = 64\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs], name = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = tf.reshape(X, shape = [-1, height, width, channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape = [None], name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_feature_maps,\n",
    "                        kernel_size=conv1_kernel_size,\n",
    "                        strides = conv1_stride, padding = conv1_pad,\n",
    "                        activation=tf.nn.relu, name = 'conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_feature_maps,\n",
    "                        kernel_size=conv2_kernel_size,\n",
    "                        strides = conv2_stride, padding = conv2_pad,\n",
    "                        activation=tf.nn.relu, name = 'conv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(64)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(32)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool3 = tf.nn.max_pool(conv2,\n",
    "                      ksize=[1,2,2,1],\n",
    "                      strides=[1,2,2,1],\n",
    "                      padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feeding the pooled result into fully connected neural network we need to flatten the pooled result\n",
    "\n",
    "pool3_flat = tf.reshape(pool3, shape = [-1, pool3_feature_maps * 7 * 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullyconn1 = tf.layers.dense(pool3_flat, n_fullyconn1, \n",
    "                             activation=tf.nn.relu, name='fc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(fullyconn1, n_outputs, name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Train accuracy :  0.99  Test accuracy :  0.9782\n",
      "1  Train accuracy :  1.0  Test accuracy :  0.9807\n",
      "2  Train accuracy :  1.0  Test accuracy :  0.9852\n",
      "3  Train accuracy :  1.0  Test accuracy :  0.9881\n",
      "4  Train accuracy :  1.0  Test accuracy :  0.9882\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 5\n",
    "batch_size = 100\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict = {X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict = {X: mnist.test.images, y:mnist.test.labels})\n",
    "        \n",
    "        print(epoch, ' Train accuracy : ', acc_train, ' Test accuracy : ', acc_test)\n",
    "        \n",
    "        save_path = saver.save(sess, './cnn_mnist_model/cnn_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
